env {
  development {
    akka.loglevel = "DEBUG"
    akka.log-dead-letters-during-shutdown = off
    http.interface = "0.0.0.0"
  }

  staging = ${env.development}

  test = ${env.development} {
    apis {
      aws {
        accessKey = ""
        secretKey = ""
        s3Bucket = ""
        s3Region = ""
      }

      elasticsearch.host = "elasticsearch://localhost:9300"

      middlewarehouse.url = ""

      stripe.key = ""
    }

    app.overrideHashPasswordAlgorithm = "plainText"

    auth.privateKey = "/auth/private_key.der"
    auth.publicKey = "/auth/public_key.der"
    auth.keyAlgorithm = "RS256"
    auth.keysLocation = "jar"

    db.url = "jdbc:postgresql://localhost/phoenix_test?user=phoenix&prepareThreshold=0"
    db.name = "phoenix_test"

    http.interface = "0.0.0.0"
    http.port = 9090

    taxRules.regionId = "4129" # California
    taxRules.rate = "7.5"

    users.admin.oauth.google {
      clientId = ""
      clientSecret = ""
      redirectUri = ""
      hostedDomain = ""
    }
    users.customer.oauth.google = {
      clientId = ""
      clientSecret = ""
      redirectUri = ""
      hostedDomain = ""
    }
  }
}

apis {
  aws {
    accessKey = ${?AWS_ACCESS_KEY}
    secretKey = ${?AWS_SECRET_KEY}
    s3Bucket = ${?S3_BUCKET}
    s3Region = ${?S3_REGION}
  }

  elasticsearch {
    host = ${?SEARCH_SERVER}
    cluster = "elasticsearch"
    index = "admin"
  }

  middlewarehouse {
    url = ${?MIDDLEWAREHOUSE_URL}
  }

  stripe {
    key = ${?STRIPE_API_KEY}
  }

  kafka {
    schemaRegistryURL = ${?SCHEMA_REGISTRY_URL}
    bootStrapServersConfig = ${?KAFKA_BROKER}
    producerTimeout = "250"
    keySerializer = "io.confluent.kafka.serializers.KafkaAvroSerializer"
    valueSerializer = "io.confluent.kafka.serializers.KafkaAvroSerializer"
  }
}

app {
  defaultContextId = 1
}

auth {
  privateKey = ${?PHOENIX_PRIVATE_KEY}
  publicKey = ${?PHOENIX_PUBLIC_KEY}
  method = "basic"
  method = ${?PHOENIX_AUTH_METHOD}

  # TODO: make it shorter (about 5 mins) after refresh-token implementation
  # in minutes, 2 days
  tokenTTL = 2880
  keyAlgorithm = "RS256"

  cookie {
    secure = on
    secure = ${?PHOENIX_COOKIE_SECURE}

    # not required, but better to set it.
    domain = ${?PHOENIX_DOMAIN}

    # in seconds, 2 days
    ttl = 172800
  }
}

http {
  interface = "0.0.0.0"
  port = ${?PORT}
}

taxRules {
  regionId = ${?TAX_RULE_REGION},
  rate = ${?TAX_RULE_RATE}
}

users.customer {
  role = "customer"
  org = "merchant"
  scopeId = 2
  oauth {
    google {
      clientId = ${?GOOGLE_OAUTH_CUSTOMER_CLIENT_ID}
      clientSecret = ${?GOOGLE_OAUTH_CUSTOMER_CLIENT_SECRET}
      redirectUri = ${?GOOGLE_OAUTH_CUSTOMER_REDIRECT_URI}
      hostedDomain = ${?GOOGLE_OAUTH_CUSTOMER_HOSTED_DOMAIN}
    }
  }
}

users.admin {
  role = "admin"
  org = "merchant"
  scopeId = 2
  oauth {
    google {
      clientId = ${?GOOGLE_OAUTH_ADMIN_CLIENT_ID}
      clientSecret = ${?GOOGLE_OAUTH_ADMIN_CLIENT_SECRET}
      redirectUri = ${?GOOGLE_OAUTH_ADMIN_REDIRECT_URI}
      hostedDomain = ${?GOOGLE_OAUTH_ADMIN_HOSTED_DOMAIN}
    }
  }
}

akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "DEBUG"
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
  server {
    remote-address-header = on
  }
}

db {
  connectionPool = HikariCP
  queueSize = 10000
  driverClassName = "org.postgresql.Driver"
  numThreads = 20
  maxConnections = 20
  leakDetectionThreshold = 60000

  host = "localhost"
  name = "phoenix_development"
  name = ${?PHOENIX_DB_NAME}
  user = "phoenix"
  baseUrl = "jdbc:postgresql://"${db.host}"/"${db.name}
  url = ${db.baseUrl}"?user="${db.user}"&prepareThreshold=0"
  driver = "slick.driver.PostgresDriver"
}
